{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIN 373N Machine Learning Toolbox for Text Analysis\n",
    "\n",
    "# Homework 4 - due Monday Nov 4 2022 at 11:59pm\n",
    "\n",
    "For this homework you will hand in (upload) to canvas:\n",
    "- a notebook renamed ``hw4_YourEID.ipynb``\n",
    "\n",
    "**Note**: This is a small homework and a perfect solution to this homework will be worth **100** points.\n",
    "\n",
    "__Before submitting__, please reset your kernel and rerun everything from the beginning (`Kernel` >> `Restart and Run All`) and ensure your code outputs the correct answer.\n",
    "\n",
    "For programming tasks, make sure that your code can run using Python 3.5+. If you cannot complete a problem, include as much pseudocode as possible for partial credit. However, make sure it does not have any output errors.Â **If there are any output errors, half of the points for that problem will be automatically deducted.**\n",
    "\n",
    "Collaboration: you are free to discuss the homework assignments with other students and work towards solutions together.  However, all of the code you write must be your own! There is a channel on Slack where you can look for a study group.\n",
    "\n",
    "Review extension and academic dishonesty policy here: https://jessyli.com/courses/lin373n\n",
    "\n",
    "For typing up your answers to non-programming problems, information can be found about Markdown cells for Jupyter Notebooks here: https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html\n",
    "\n",
    "\n",
    "### Please list any collaborators here:\n",
    "- \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Multi-layer perceptron going linear (10 points)\n",
    "\n",
    "Show mathematically that a multi-layer perceptron using the _linear (identity) activation function_ $y=z$ is still a linear classifier. You can assume that (1) each example has two features $x_1$ and $x_2$; (2) there are two hidden layers; (3) each hidden layer has two nodes; (4) this is for a binary classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we would be using a linear activation function, then it is clear that the multi-layer perceptron model will be a linear classifier since it would be a linear combination so it would still be a linear function in the end. So, each layer having a linear function as output will result in another linear function when it is the input to the next layer. I hope I explained this clearly, but basically it can only be a linear classifier since it is only working with linear functions and linear combinations.\n",
    "\n",
    "* First node in first layer: Weights are w1, w2 and bias is b1\n",
    "* Second node in first layer: Weights are w3, w4 and bias is b2\n",
    "* First node in second layer: Weights are v1, v2 and bias is b3\n",
    "* Second node in second layer: Weights are v3, v4 and bias is b4\n",
    "\n",
    "#### First hidden layer ####\n",
    "- Node 1: w1 * x1 + w2 * x2 + b1 \n",
    "- Node 2: w3 *  x1 + w4 * x2 + b2\n",
    "\n",
    "#### Second hidden layer ####\n",
    "* Node 1: v1 * (w1 * x1 + w2 * x2 + b1) + v2 * (w3 * x1 + w4 * x2 + b2) + b3\n",
    "* Node 2: v3 * (w1 * x1 + w2 * x2 + b1) + v4 * (w3 * x1 + w4 * x2 + b2) + b4\n",
    "\n",
    "#### Final layer ####\n",
    "* Add linear functions: v1 * (w1 * x1 + w2 * x2 + b1) + v2 * (w3 * x1 + w4 * x2 + b2) + b3 + v3 * (w1 * x1 + w2 * x2 + b1) + v4 * (w3 * x1 + w4 * x2 + b2) + b4\n",
    "* This will result in a linear function, thus this will still be a linear classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Concepts (30 points)\n",
    "Briefly answer the following questions:\n",
    "\n",
    "**(1)** What is batching in neural networks, and why batching is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batching is splitting up large amounts of data into smaller amounts, or batches. Then, each batch goes through the neural network. Batching is done in order to increase speed, decrease memory usage, and overall make it easier for the CPU to handle the data. Batching is often used to train neural networks faster and also for better accuracy, such as in mini-batch gradient descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2)** Name and describe two ways to prevent overfitting in a deep neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Dropout regularization:** In this method, we randomly set activations to zero (thus 'dropping' them) and this process continues throughout training. Often, this is about 50% of the activations in a layer. This prevents overfitting because the neural network doesn't depend on just one node. The networks learns to generalize.\n",
    "2. **Early stopping:** The goal of this method is to stop training the network before it overfits. Using a validation set in addition to the training set, we mark the point right before the loss on the validation set starts increasing and the loss on the training set decreases, since this is where the network starts to overfit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3)** Name at least one benefit of using static word embeddings (e.g., glove, word2vec) over bag-of-words representations, and at least one aspect of language that word embeddings do not account for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One aspect of language that word embeddings do not account for is that words can have multiple senses. For example, with the word 'apple' we might get a vector that groups it closer to words related to the tech company rather than the fruit. One benefit of using static word embeddings over bag-of-words representations is that in bag-of-words, you may not have accurate representations in terms of meaning because it is based on the frequency counts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4)** What's a key difference between static word embeddings (e.g., glove, word2vec) and contextualized word embeddings (e.g., BERT, Elmo)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Static word embeddings do not take context into account, so we end up with only one context for each word (like tech company for the word 'apple) and thus only one embedding. Contextualized word embeddings make having different embeddings for the words that have a different meaning depending on the context. Thus, in a visualization, you may find the word 'bank' or 'apple' multiple times as it considers the different contexts it appears in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5)** Suppose we are considering a tweet classification task on 8000 examples. A common way to obtain a prepresentation of one tweet via word embeddings is to take the average of the embeddings of each token within this tweet. Suppose we are designing a neural network with:\n",
    "* Word embeddings of 300 dimensions; \n",
    "* A first hidden layer with 100 hidden states;\n",
    "* A second hidden layer with 10 hidden states;\n",
    "* A final binary classification layer.\n",
    "\n",
    "How many parameters will the network learn? Show your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ( 300 * 100 ) + 100 = 30,100\n",
    "2. ( 100 * 10 ) + 10 = 1,010\n",
    "3. ( 10 * 2 ) + 2 = 22\n",
    "- Total number of parameters to learn: 30,100 + 1,010 + 22 = 31,132"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Bias in word embeddings (15 points)\n",
    "\n",
    "It's important to be cognizant of the biases (gender, race, sexual orientation etc.) implicit in our word embeddings. Bias can be dangerous because it can reinforce stereotypes through applications that employ these models.\n",
    "\n",
    "Here, we shall explore the embeddings produced by GloVe. Please revisit the class notes and lecture slides for more details on the word2vec and GloVe algorithms.\n",
    "\n",
    "Then run the following cells to load the GloVe vectors into memory. **Note**: If this is your first time to run these cells, i.e. download the embedding model, it will take a couple minutes to run. If you've run these cells before, rerunning them will load the model without redownloading it, which will take about 1 to 2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocab size 400000\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "def load_embedding_model():\n",
    "    \"\"\" Load GloVe Vectors\n",
    "        Return:\n",
    "            wv_from_bin: All 400000 embeddings, each lengh 200\n",
    "    \"\"\"\n",
    "    \n",
    "    wv_from_bin = api.load(\"glove-wiki-gigaword-200\")\n",
    "    print(\"Loaded vocab size %i\" % len(wv_from_bin.key_to_index))\n",
    "    return wv_from_bin\n",
    "\n",
    "# -----------------------------------\n",
    "# Run Cell to Load Word Vectors\n",
    "# Note: This will take a couple minutes\n",
    "# -----------------------------------\n",
    "wv_from_bin = load_embedding_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1)** Run the cell below, to examine (a) which terms are most similar to \"woman\" and \"worker\" and most dissimilar to \"man\", and (b) which terms are most similar to \"man\" and \"worker\" and most dissimilar to \"woman\". **Point out the difference between the list of female-associated words and the list of male-associated words, and explain how it is reflecting gender bias.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('employee', 0.6375863552093506), ('workers', 0.6068919897079468), ('nurse', 0.5837947130203247), ('pregnant', 0.5363885164260864), ('mother', 0.5321308374404907), ('employer', 0.5127025246620178), ('teacher', 0.5099577307701111), ('child', 0.5096741318702698), ('homemaker', 0.5019454956054688), ('nurses', 0.4970572888851166)]\n",
      "\n",
      "[('workers', 0.6113258004188538), ('employee', 0.5983108282089233), ('working', 0.5615329146385193), ('laborer', 0.5442320108413696), ('unemployed', 0.536851704120636), ('job', 0.5278826355934143), ('work', 0.5223963260650635), ('mechanic', 0.5088937282562256), ('worked', 0.505452036857605), ('factory', 0.49404534697532654)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this cell\n",
    "# Here `positive` indicates the list of words to be similar to and `negative` indicates the list of words to be\n",
    "# most dissimilar from.\n",
    "print(wv_from_bin.most_similar(positive=['woman', 'worker'], negative=['man']))\n",
    "print()\n",
    "print(wv_from_bin.most_similar(positive=['man', 'worker'], negative=['woman']))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The female-associated words include nurse, pregnant, mother, teacher, child, and homemaker. On the other hand, the male-associated words include laborer, job, mechanic, unemployed, and factory. This reflects gender bias as they are words that both genders can do but these associations imply otherwise since we essentially 'subtracted' the opposite gender. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2)** Now, Use the most_similar function to find another case where some bias is exhibited by the vectors. Please briefly explain the example of bias that you discover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('unemployed', 0.526461660861969), ('hispanic', 0.5242168307304382), ('migrant', 0.5187416076660156), ('immigrant', 0.49582335352897644), ('laborer', 0.4925740361213684), ('workers', 0.45766526460647583), ('laborers', 0.4453660249710083), ('undocumented', 0.4415454566478729), ('employee', 0.4386615455150604), ('blue-collar', 0.4296375513076782)]\n",
      "\n",
      "[('employee', 0.5921893119812012), ('workers', 0.558663547039032), ('soldier', 0.5542395710945129), ('working', 0.55413818359375), ('u.s.', 0.552578866481781), ('another', 0.5124087929725647), ('woman', 0.5105667114257812), ('nurse', 0.5081354975700378), ('old', 0.5046603679656982), ('worked', 0.5042327046394348)]\n",
      "\n",
      "Explanation: We can see bias here with the words most similar to 'latino' and 'worker' as opposed to 'american' and 'worker.' For the former, we see words like unemployed, migrant, immigrant, blue-collar and undocumented. For the latter, words like soldier and nurse show up. I think this uncovers some kind of bias specifically against Latinos as workers. Even though there are plenty of Latino workers outside of blue-collar jobs and that are not immigrants, the most similar words show otherwise. We know that there exists a stereotype for them and I think these vectors exhibit that bias and stereotype. \n"
     ]
    }
   ],
   "source": [
    "print(wv_from_bin.most_similar(positive=['latino', 'worker'], negative=['american']))\n",
    "print()\n",
    "print(wv_from_bin.most_similar(positive=['american', 'worker'], negative=['latino']))\n",
    "print()\n",
    "print(\"Explanation: We can see bias here with the words most similar to 'latino' and 'worker' as opposed to 'american' and 'worker.' For the former, we see words like unemployed, migrant, immigrant, blue-collar and undocumented. For the latter, words like soldier and nurse show up. I think this uncovers some kind of bias specifically against Latinos as workers. Even though there are plenty of Latino workers outside of blue-collar jobs and that are not immigrants, the most similar words show otherwise. We know that there exists a stereotype for them and I think these vectors exhibit that bias and stereotype. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3)** Give one explanation of how bias gets into the word vectors. What is an experiment that you could do to test for or to measure this source of bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias gets into word vectors since they are trained on data that is fundamentally biased since there exists a cultural bias already against some groups of people. Thus, we could potentially get different word embeddings based on different data that is culturally different, each having their own cultural bias. Perhaps we could then see what words are biased if their associations differ across cultures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Multi-layer perceptron in sklearn (45 points)\n",
    "\n",
    "(a) (9 points) Using the Logistic Regression model you implemented in homework 3 as a starting point, modify this to use the [Multi-layer Perceptron model provided by sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) as the learning algorithm. How do the two models compare in terms of predictive performance (accuracy)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "dataset = load_files(\"movie-reviews/\")\n",
    "# generate train/test subsets\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size = 0.2, random_state = 3)\n",
    "vectorizer = CountVectorizer(stop_words = \"english\")\n",
    "X_train = vectorizer.fit_transform(docs_train)\n",
    "X_test = vectorizer.transform(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model accuarcy: 0.8725\n",
      "LR model accuracy: 0.8475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "mlp_model = MLPClassifier(random_state = 3)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "y_hat_mlp = mlp_model.predict(X_test)\n",
    "mlp_acc = mlp_model.score(X_test, y_test)\n",
    "accuracy_score_mlp = metrics.accuracy_score(y_test, y_hat_mlp)\n",
    "\n",
    "lr_model = LogisticRegression(random_state = 3, solver = 'liblinear')\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_hat_lr = lr_model.predict(X_test)\n",
    "accuracy_score_lr = metrics.accuracy_score(y_test, y_hat_lr)\n",
    "\n",
    "print('MLP model accuarcy: ' + str(accuracy_score_mlp))\n",
    "print('LR model accuracy: ' + str(accuracy_score_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In terms of accuracy, the MLP model performs slightly better than the LR model.\n"
     ]
    }
   ],
   "source": [
    "print('In terms of accuracy, the MLP model performs slightly better than the LR model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(lr_model.solver == 'liblinear')\n",
    "assert(lr_model.random_state == 3)\n",
    "assert(mlp_model.random_state == 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) (9x4=36 points) Note that when you build the MLPClassifier, you will see a series of parameters printed out with the classifier. Consider the following parameters, modify them, and see how performance and/or training speed changes:\n",
    "\n",
    "**Note** that you should modify _only one_ parameter at a time! Additionally,  clearly label each time you test a parameter.\n",
    "\n",
    "(b.1) Turn early stopping on or off. **Also answer: what does early stopping do?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after turning early stopping on: 0.865\n"
     ]
    }
   ],
   "source": [
    "mlp_model = MLPClassifier(random_state = 3, early_stopping = True)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "y_hat_mlp = mlp_model.predict(X_test)\n",
    "mlp_acc = mlp_model.score(X_test, y_test)\n",
    "accuracy_score_mlp = metrics.accuracy_score(y_test, y_hat_mlp)\n",
    "\n",
    "print('Accuracy after turning early stopping on: ' + str(accuracy_score_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping is a method of preventing overfitting. Turning early stopping on lowered the accuracy than having it off, but only slightly. In terms of speed, I did notice it took longer to finish running everything.\n"
     ]
    }
   ],
   "source": [
    "print('Early stopping is a method of preventing overfitting. Turning early stopping on lowered the accuracy than having it off, but only slightly. In terms of speed, I did notice it took longer to finish running everything.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b.2) Play with other activation functions. How does that affect performance? (identity, logistic, tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using identity activation: 0.865\n",
      "Accuracy using tanh activation: 0.87\n",
      "Accuracy using logistic activation: 0.8725\n"
     ]
    }
   ],
   "source": [
    "mlp_model = MLPClassifier(random_state = 3, activation = 'identity')\n",
    "mlp_model.fit(X_train, y_train)\n",
    "y_hat_mlp = mlp_model.predict(X_test)\n",
    "mlp_acc = mlp_model.score(X_test, y_test)\n",
    "acc_id = metrics.accuracy_score(y_test, y_hat_mlp)\n",
    "print('Accuracy using identity activation: ' + str(acc_id))\n",
    "\n",
    "mlp_model = MLPClassifier(random_state = 3, activation = 'tanh')\n",
    "mlp_model.fit(X_train, y_train)\n",
    "y_hat_mlp = mlp_model.predict(X_test)\n",
    "mlp_acc = mlp_model.score(X_test, y_test)\n",
    "acc_tanh = metrics.accuracy_score(y_test, y_hat_mlp)\n",
    "print('Accuracy using tanh activation: ' + str(acc_tanh))\n",
    "\n",
    "mlp_model = MLPClassifier(random_state = 3, activation = 'logistic')\n",
    "mlp_model.fit(X_train, y_train)\n",
    "y_hat_mlp = mlp_model.predict(X_test)\n",
    "mlp_acc = mlp_model.score(X_test, y_test)\n",
    "acc_log = metrics.accuracy_score(y_test, y_hat_mlp)\n",
    "print('Accuracy using logistic activation: ' + str(acc_log))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The logistic activation function performs the same in terms of accuracy as the original model, which uses relu. Using the tanh activation function, we get a slightly lower accuracy. As for the identity function, it is the lowest of all functions, but performs only slightly worse in terms of accuracy. In terms of speed, I think they all took about the same time to run and it didn't take too long.\n"
     ]
    }
   ],
   "source": [
    "print('The logistic activation function performs the same in terms of accuracy as the original model, which uses relu. Using the tanh activation function, we get a slightly lower accuracy. As for the identity function, it is the lowest of all functions, but performs only slightly worse in terms of accuracy. In terms of speed, I think they all took about the same time to run and it didn\\'t take too long.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b.3) By default, MLPClassifier uses the *adam* algorithm to find weights, which is an adaptive method with changing learning rates. You can also choose stochastic gradient descent (sgd). Try it; how does sgd perform, compared with adam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using stochastic gradient descent: 0.8375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\veron\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp_model = MLPClassifier(random_state = 3, solver = 'sgd')\n",
    "mlp_model.fit(X_train, y_train)\n",
    "y_hat_mlp = mlp_model.predict(X_test)\n",
    "mlp_acc = mlp_model.score(X_test, y_test)\n",
    "acc_sgd = metrics.accuracy_score(y_test, y_hat_mlp)\n",
    "\n",
    "print('Using stochastic gradient descent: ' + str(acc_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared to adam, using stochastic gradient descent performs worse in terms of accuracy. I think the speed took around the same as using adam.\n"
     ]
    }
   ],
   "source": [
    "print('Compared to adam, using stochastic gradient descent performs worse in terms of accuracy. I think the speed took around the same as using adam.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b.4) Experiment with different learning rates (parameter `learning_rate_init`), for example, try 0.1, 0.01, 0.0001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using learning rate of 0.1: 0.79\n",
      "Using learning rate of 0.01: 0.8575\n",
      "Using learning rate of 0.0001: 0.875\n"
     ]
    }
   ],
   "source": [
    "mlp_model = MLPClassifier(random_state = 3, learning_rate_init = 0.1)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "y_hat_mlp = mlp_model.predict(X_test)\n",
    "mlp_acc = mlp_model.score(X_test, y_test)\n",
    "acc_1 = metrics.accuracy_score(y_test, y_hat_mlp)\n",
    "print('Using learning rate of 0.1: ' + str(acc_1))\n",
    "\n",
    "mlp_model = MLPClassifier(random_state = 3, learning_rate_init = 0.01)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "y_hat_mlp = mlp_model.predict(X_test)\n",
    "mlp_acc = mlp_model.score(X_test, y_test)\n",
    "acc_01 = metrics.accuracy_score(y_test, y_hat_mlp)\n",
    "print('Using learning rate of 0.01: ' + str(acc_01))\n",
    "\n",
    "mlp_model = MLPClassifier(random_state = 3, learning_rate_init = 0.0001)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "y_hat_mlp = mlp_model.predict(X_test)\n",
    "mlp_acc = mlp_model.score(X_test, y_test)\n",
    "acc_0001 = metrics.accuracy_score(y_test, y_hat_mlp)\n",
    "print('Using learning rate of 0.0001: ' + str(acc_0001))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When adjusting the learning rate, the higher the learning rate, the higher the accuracy. The 0.0001 learning rate was only slightly better than the default. In terms of speed, I found that it took longer as the learning rate got smaller.\n"
     ]
    }
   ],
   "source": [
    "print('When adjusting the learning rate, the higher the learning rate, the higher the accuracy. The 0.0001 learning rate was only slightly better than the default. In terms of speed, I found that it took longer as the learning rate got smaller.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
